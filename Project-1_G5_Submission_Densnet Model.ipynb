{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                       **CIFAR-10: Image Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#   Step 1: Data Preprocessing & Loading \n",
    "##  Visualization of Images and Labels / Inserting Grayscale Conversion / Augmentation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%pip install matplotlib\n",
    "%pip install numpy\n",
    "%pip install tensorflow\n",
    "%pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, RandomFlip, RandomRotation\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CIFAR-10 Dataset\n",
    "(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data dimensions\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list with all the class labels for CIFAR-10\n",
    "classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "\n",
    "# Function to visualize color images from CIFAR-10 dataset with correct labeling\n",
    "def visualize_color_images_with_labels(images, labels, classes, images_per_class=10, title=\"CIFAR-10 Images\"):\n",
    "    num_classes = len(classes)\n",
    "    total_images = num_classes * images_per_class\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    image_count = 0\n",
    "\n",
    "    # Loop through class labels to pick images_per_class images per class\n",
    "    for class_index, class_name in enumerate(classes):\n",
    "        class_images = images[labels.flatten() == class_index][:images_per_class]\n",
    "\n",
    "        # Loop through the images, arranging them dynamically\n",
    "        for img in class_images:\n",
    "            plt.subplot(num_classes, images_per_class, image_count + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Add class label to the left side of each row\n",
    "            if image_count % images_per_class == 0:\n",
    "                plt.text(-30, 32 // 2, class_name, rotation=0, size='large', va='center', ha='right')\n",
    "            \n",
    "            image_count += 1\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize color images from the CIFAR-10 training set\n",
    "visualize_color_images_with_labels(x_train, y_train, classes, images_per_class=10, title=\"CIFAR-10 Training Images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert images to grayscale (Not in use because of DenseNet)\n",
    "\n",
    "grayscale_x_train = tf.image.rgb_to_grayscale(x_train)\n",
    "grayscale_x_test = tf.image.rgb_to_grayscale(x_test)\n",
    "\n",
    "gray_x_train = np.array(grayscale_x_train)\n",
    "gray_x_test = np.array(grayscale_x_test)\n",
    "\n",
    "print(gray_x_train.shape)\n",
    "print(gray_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation:\n",
    "\n",
    "\n",
    "\n",
    "# Create augmentation layer for model (used further down)\n",
    "\n",
    "data_augmentation = Sequential([\n",
    "layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "layers.RandomRotation(0.2),\n",
    "]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the images to the range [0, 1]\n",
    "x_train_normalized = x_train.astype('float32') / 255.0\n",
    "x_test_normalized = x_test.astype('float32') / 255.0\n",
    "\n",
    "print(x_train_normalized.shape)\n",
    "print(x_test_normalized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_test = to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task, Diego:\n",
    "Transfer Traning (VGG-16 can work well, imagenit, inseption, densnet, resnet) Check which one is the most efficient to clasify our image model.\n",
    "Build a model Densnet\n",
    "- Research different networks to see what kind of data they were trained on (image classes, how many...?)\n",
    "- Decide on best one for our dataset\n",
    "- Think about how many layers to add on top of that for our specific model\n",
    "- Think about which layers to freeze/ unfreeze when training with the new layers\n",
    "- Adjust epochs, other parameters related to our new model which could optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DenseNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import DenseNet121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained DenseNet121 model\n",
    "#base_model = DenseNet121(weights='imagenet', include_top=False)\n",
    "\n",
    "# Load DenseNet121 with pre-trained ImageNet weights, excluding the top layer\n",
    "base_model = DenseNet121(include_top=False, weights='imagenet', input_shape=(32, 32, 3), pooling='avg')\n",
    "\n",
    "# Adding custom Top layers that will be trained for CIFAR-10 classification\n",
    "# Add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully connected layer\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "# Add the output layer\n",
    "predictions = Dense(10, activation='softmax')(x)\n",
    "\n",
    "# Create the final model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Define the data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True,\n",
    "                                  vertical_flip=True,\n",
    "                                  rotation_range=20)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow(x_train_normalized, y_train, batch_size=32)\n",
    "val_generator = val_datagen.flow(x_test_normalized, y_test, batch_size=32)\n",
    "\n",
    "# Train the model\n",
    "model.fit_generator(train_generator,\n",
    "                  steps_per_epoch=100,\n",
    "                  epochs=10,\n",
    "                  validation_data=val_generator,\n",
    "                  validation_steps=50)\n",
    "\n",
    "# Use the model to make predictions\n",
    "predictions = model.predict(x_test_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load DenseNet121 with pre-trained ImageNet weights, excluding the top layer\n",
    "base_model = DenseNet121(include_top=False, weights='imagenet', input_shape=(32, 32, 3), pooling='avg')\n",
    "\n",
    "# Make the base model non-trainable\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    Dense(10, activation='softmax')  # CIFAR-10 has 10 classes\n",
    "])\n",
    "\n",
    "# Show model structure\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=64),\n",
    "                    steps_per_epoch=len(x_train) / 64, epochs=10,\n",
    "                    validation_data=(x_test, y_test))\n",
    "\n",
    "\n",
    "    # Unfreeze the top 50 layers of the model\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# It's important to recompile the model after you make any changes to the 'trainable' attribute of any inner layer, so that your changes are taken into account\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),  # Lower learning rate\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, RandomFlip, RandomRotation, BatchNormalization, Activation\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Step 4: Model Evaluation\n",
    "## Evaluate the Model and Compute Metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
